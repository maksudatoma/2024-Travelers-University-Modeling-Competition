
---
title: "Final Report"
format:
  pdf:
    keep-tex: true
    documentclass: article
    papersize: letter
    fontsize: 10pt
    template-partials:
      - title.tex
      - before-bib.tex
    include-in-header:
      - text: |
          \usepackage{sdss2020} % Uses Times Roman font (either newtx or times package)
          \usepackage{url}
          \usepackage{hyperref}
          \usepackage{latexsym}
          \usepackage{amsmath, amsthm, amsfonts}
          \usepackage{algorithm, algorithmic}
          \usepackage[dvipsnames]{xcolor} % colors
          \newcommand{\mt}[1]{{\textcolor{blue}{#1}}}
          \newcommand{\svp}[1]{{\textcolor{RedOrange}{#1}}}
    classoption: [twocolumn]
    mainfont: Times New Roman
    colorlinks: true

author:
  - name: "Maksuda Aktar Toma"
    affiliation: "Statistics Department, University of Nebraska, Lincoln"
    email: "mtoma2@huskers.unl.edu"
    corresponding: true
  
  - name: "Aarif Baksh"
    affiliation: "Statistics Department, University of Nebraska, Lincoln"
    email: "abaksh2@unl.edu"
    corresponding: true
    orcid: "0000-0002-3803-0972"
bibliographystyle: acl
bibliography: refs.bib
filters:
  - latex-environment
commands: [mt, svp]

---

## Business Problem

As an employee of CloverShield Insurance company, you are tasked with addressing the challenge of reducing call center costs. Your business partners have requested the development of a predictive model that, based on the provided segmentation, forecasts the number of times a policyholder is likely to call. This model aims to optimize resource allocation and enhance cost-efficiency in call center operations.

To find all our works on this project go to this link <https://github.com/maksudatoma/2024-Travelers-University-Modeling-Competition/tree/main>

## Introduction

The data obtained from Kaggle, is split into two parts: training data and validation data. In the validation data, the target variable, call_counts, is omitted. The training dataset contains 80,000 samples, and the validation dataset contains 20,000 samples.

**Variable Descriptions**

-   `ann_prm_amt`: Annualized Premium Amount

-   `bi_limit_group`: Body injury limit group (SP stands for single split limit coverage, CSL stands for combined single limit coverage)

-   `channel`: Distribution channel

-   `newest_veh_age`: The age of the newest vehicle insured on a policy (-20 represents non-auto or missing values)

-   `geo_group`: Indicates if the policyholder lives in a rural, urban, or suburban area

-   `has_prior_carrier`: Did the policyholder come from another carrier

-   `home_lot_sq_footage`: Square footage of the policyholder's home lot

-   `household_group`: The types of policy in household

-   `household_policy_counts`: Number of policies in the household

-   `telematics_ind`: Telematic indicator (0 represents auto missing values or didn't enroll and -2 represents non-auto)

-   `digital_contacts_ind`: An indicator to denote if the policy holder has opted into digital communication

-   `12m_call_history`: Past one year call count

-   `tenure_at_snapshot`:Policy active length in month

-   `pay_type_code`: Code indicating the payment method

-   `acq_method`:The acquisition method (Miss represents missing values)

-   `trm_len_mo`: Term length month

-   `pol_edeliv_ind`: An indicator for email delivery of documents (-2 represents missing values)

-   `aproduct_sbtyp_grp`: Product subtype group

-   `product_sbtyp`: Product subtype

-   `call_counts`: The number of call count generated by each policy (target variable)

## Data Cleaning and Missing Value count

First, we prepares the data by cleaning and transforming it (e.g., converting characters to factors, marking missing values.)

| Variable       | Number of missing values |
|----------------|--------------------------|
| acq_method     | 16,066                   |
| newest_veh_age | 58,015                   |
| pol_edeliv_ind | 838                      |
| telematics_ind | 58,015                   |

: **Table 1: Variables with Missing Values**

**Zero Values:** 50.18% of the rows in the call_counts column are zeros, indicating that most customers made no calls. This is significant and might suggest using models like Zero-Inflated Poisson (ZIP) to handle the high frequency of zeros.

**Key Takeaways** - The dataset contains both numeric and categorical variables, with some columns having significant missing values. - The target variable (call_counts) is heavily zero-inflated and skewed, which may require specialized modeling approaches. - Some numeric variables, like ann_prm_amt and home_lot_sq_footage, have wide ranges and outliers, suggesting that data transformation or scaling may be beneficial.
